{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports and set torch device\n",
    "import numpy as np\n",
    "import meshplot as mp\n",
    "import matplotlib.pyplot as plt\n",
    "import kaolin as kal\n",
    "import cv2\n",
    "from collections import defaultdict\n",
    "import trimesh\n",
    "from scipy.spatial.distance import cdist\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda:0\")\n",
    "    torch.cuda.set_device(device)\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "\n",
    "print('Torch will run on:', device)\n",
    "\n",
    "object = 'bookshelf' \n",
    "obj_path = 'data/demo/' + object + '.obj'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read Mesh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read mesh\n",
    "mesh = kal.io.obj.import_mesh(\n",
    "    obj_path,\n",
    "    with_normals=True,\n",
    "    with_materials=False,\n",
    ")\n",
    "\n",
    "vertices_tensor = mesh.vertices.to(device)\n",
    "faces_tensor = mesh.faces.to(device)\n",
    "\n",
    "vertices = vertices_tensor.detach().cpu().numpy()\n",
    "faces = faces_tensor.detach().cpu().numpy()\n",
    "colors =  mesh.vertex_normals.cpu().numpy()\n",
    "\n",
    "print('Number of vertices: ', vertices.shape[0])\n",
    "print('Number of faces: ', faces.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sample Points on mesh surface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize mesh\n",
    "trimeshMesh = trimesh.Trimesh(vertices, faces)\n",
    "N = int(vertices.shape[0] * 2)\n",
    "# N = int(vertices.shape[0] / 2)\n",
    "point_cloud, pt_to_face = trimesh.sample.sample_surface_even(trimeshMesh, N)\n",
    "torchPC = torch.tensor(point_cloud, device=torch.device('cuda:0'), dtype=torch.float32)\n",
    "face_to_all_pts = defaultdict(list)\n",
    "for pt in range(len(point_cloud)):\n",
    "    face_to_all_pts[pt_to_face[pt]].append(pt)\n",
    "p = mp.plot(vertices, faces, colors, return_plot=True, shading={\"wireframe\": 0.1})\n",
    "p.add_points(point_cloud, shading={\"point_size\": 0.1, \"point_color\": \"green\"})\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define rendering functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "width = 1024; height = 1024 \n",
    "def get_camera_from_view2(elev, azim, r=3.0):\n",
    "    x = r * torch.cos(elev) * torch.cos(azim)\n",
    "    y = r * torch.sin(elev)\n",
    "    z = r * torch.cos(elev) * torch.sin(azim)\n",
    "    pos = torch.tensor([x, y, z]).unsqueeze(0)\n",
    "    look_at = - pos\n",
    "    direction = torch.tensor([0.0, 1.0, 0.0]).unsqueeze(0)\n",
    "    camera_proj = kal.render.camera.generate_transformation_matrix(pos, look_at, direction)\n",
    "    return camera_proj\n",
    "\n",
    "def get_camera_properties(elev, azim, r):\n",
    "    x = r * torch.cos(elev) * torch.cos(azim)\n",
    "    y = r * torch.sin(elev)\n",
    "    z = r * torch.cos(elev) * torch.sin(azim)\n",
    "    eye = torch.tensor([x, y, z], device=device)\n",
    "    look_at = - eye\n",
    "    look_at /= torch.norm(look_at)\n",
    "    up = torch.tensor([0.0, 1.0, 0.0], device=device)\n",
    "    right = torch.cross(look_at, up)\n",
    "    right /= torch.norm(right)\n",
    "    up = torch.cross(right, look_at)\n",
    "    up /= torch.norm(up)\n",
    "    return eye, look_at, up, right\n",
    "\n",
    "def render_view(elev, azim, r):\n",
    "    background = torch.tensor([255.0, 255.0, 255.0]).to(device)\n",
    "    # face_attributes = kal.ops.mesh.index_vertices_by_faces(\n",
    "    #     torch.ones(1, len(mesh.vertices), 3).to(device)\n",
    "    #     * torch.tensor([0.5, 0.5, 0.5]).unsqueeze(0).unsqueeze(0).to(device),\n",
    "    #     faces_tensor,\n",
    "    # )\n",
    "    face_attributes = kal.ops.mesh.index_vertices_by_faces(\n",
    "            mesh.vertex_normals.unsqueeze(0).to(device),\n",
    "            faces_tensor\n",
    "    ) \n",
    "    face_attributes = [\n",
    "        face_attributes,  # Colors\n",
    "        torch.ones((1, faces.shape[0], 3, 1), device=device),  # hard seg. mask\n",
    "    ]\n",
    "    \n",
    "    camera_projection = kal.render.camera.generate_perspective_projection(np.pi / 3).to(device)\n",
    "    camera_transform = get_camera_from_view2(elev, azim, r=r).to(device)\n",
    "    (\n",
    "        face_vertices_camera,\n",
    "        face_vertices_image,\n",
    "        face_normals,\n",
    "    ) = kal.render.mesh.prepare_vertices(\n",
    "        mesh.vertices.to(device),\n",
    "        mesh.faces.to(device),\n",
    "        camera_projection,\n",
    "        camera_transform=camera_transform,\n",
    "    )\n",
    "\n",
    "    # v = mesh.vertices[faces[0, 0]].to(device).unsqueeze(0)\n",
    "    # v = torch.cat((v, torch.tensor([[1]], device=device)), 1)\n",
    "    # print(face_vertices_camera.squeeze()[0, 0].unsqueeze(0))\n",
    "    # print(torch.mm(v, camera_transform.squeeze()))\n",
    "    # print(face_vertices_image[0,0,0])\n",
    "\n",
    "    image_features, soft_mask, face_idx = kal.render.mesh.dibr_rasterization(\n",
    "        1024,\n",
    "        1024,\n",
    "        face_vertices_camera[:, :, :, -1],\n",
    "        face_vertices_image,\n",
    "        face_attributes,\n",
    "        face_normals[:, :, -1],\n",
    "    )\n",
    "\n",
    "    image_features, mask = image_features\n",
    "    image = torch.clamp(image_features, 0.0, 1.0)\n",
    "    lights=torch.tensor([1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0]).unsqueeze(0).to(device)\n",
    "    image_normals = face_normals[:, face_idx].squeeze(0)\n",
    "    image_lighting = kal.render.mesh.spherical_harmonic_lighting(\n",
    "        image_normals, lights\n",
    "        ).unsqueeze(0)\n",
    "    image = image * image_lighting.repeat(1, 3, 1, 1).permute(\n",
    "        0, 2, 3, 1\n",
    "        ).to(device)\n",
    "    image = torch.clamp(image, 0.0, 1.0)\n",
    "    background_mask = torch.zeros(image.shape).to(device)\n",
    "    mask = mask.squeeze(-1)\n",
    "    background_idx = torch.where(mask == 0)\n",
    "    assert torch.all(\n",
    "        image[background_idx] == torch.zeros(3).to(device)\n",
    "    )  # Remvoe it may be taking a lot of time\n",
    "    background_mask[\n",
    "        background_idx\n",
    "    ] = background  # .repeat(background_idx[0].shape)\n",
    "    image = torch.clamp(image + background_mask, 0.0, 1.0)\n",
    "    image = image.squeeze().cpu().numpy()\n",
    "    image *= 255.0\n",
    "    image = image.astype(np.uint8)\n",
    "    return image, face_idx\n",
    "\n",
    "from SAM import SamPredictor, sam_model_registry\n",
    "sam = sam_model_registry[\"vit_h\"](checkpoint=\"./SAM/MODEL/sam_vit_h_4b8939.pth\")\n",
    "predictor = SamPredictor(sam)\n",
    "def show_mask(mask, ax, random_color=False):\n",
    "    if random_color:\n",
    "        color = np.concatenate([np.random.random(3), np.array([0.6])], axis=0)\n",
    "    else:\n",
    "        color = np.array([30/255, 144/255, 255/255, 0.6])\n",
    "    h, w = mask.shape[-2:]\n",
    "    mask_image = mask.reshape(h, w, 1) * color.reshape(1, 1, -1)\n",
    "    ax.imshow(mask_image)\n",
    "    \n",
    "def show_points(coords, labels, ax, marker_size=375):\n",
    "    pos_points = coords[labels==1]\n",
    "    neg_points = coords[labels==0]\n",
    "    ax.scatter(pos_points[:, 0], pos_points[:, 1], color='green', marker='*', s=marker_size, edgecolor='white', linewidth=1.25)\n",
    "    ax.scatter(neg_points[:, 0], neg_points[:, 1], color='red', marker='*', s=marker_size, edgecolor='white', linewidth=1.25)   \n",
    "    \n",
    "def show_box(box, ax):\n",
    "    x0, y0 = box[0], box[1]\n",
    "    w, h = box[2] - box[0], box[3] - box[1]\n",
    "    ax.add_patch(plt.Rectangle((x0, y0), w, h, edgecolor='green', facecolor=(0,0,0,0), lw=2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute Normals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def computeNormals(mesh, pt_to_face):\n",
    "    face_normals = kal.ops.mesh.face_normals(\n",
    "        kal.ops.mesh.index_vertices_by_faces(mesh.vertices.unsqueeze(0), mesh.faces), unit=True).squeeze()\n",
    "    n_pts = len(pt_to_face)\n",
    "    pts_normals = torch.zeros((n_pts, 3), device = device)\n",
    "    for pt in range(n_pts):\n",
    "        pts_normals[pt] = face_normals[pt_to_face[pt]]\n",
    "    return pts_normals\n",
    "\n",
    "pts_normals = computeNormals(mesh, pt_to_face)\n",
    "mp.plot(point_cloud, c = pts_normals.cpu().numpy(), shading={'point_size':0.15})\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_ray_direction = torch.tensor([[1,0,0]], device=device, dtype=torch.float32)\n",
    "dot_prod = torch.mm(pts_normals, m_ray_direction.T).squeeze()\n",
    "colors = torch.zeros((dot_prod.shape[0], 3), dtype=torch.float32)\n",
    "colors[dot_prod > 0] = torch.tensor([1, 0, 0], dtype=torch.float32)\n",
    "mp.plot(point_cloud, c = colors.cpu().numpy(), shading={'point_size':0.1})\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build SPC from Point Cloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Our SPC will contain a hierarchy of multiple levels\n",
    "level = 8\n",
    "torch.manual_seed(0)\n",
    "# colors = torch.rand(point_cloud.shape[0], 3, device=device)\n",
    "# colors = torch.tensor(point_cloud, device=device)\n",
    "# colors = torch.tensor(point_cloud[:,:1]).to(device)\n",
    "colors = torch.arange(0, point_cloud.shape[0]).unsqueeze(1).to(device)\n",
    "# mp.plot(point_cloud, c = colors.cpu().numpy(), shading={'point_size':0.2})\n",
    "# plt.show()\n",
    "spc = kal.ops.conversions.pointcloud.unbatched_pointcloud_to_spc(\n",
    "    pointcloud=torchPC, level=level, features=colors)\n",
    "octree, features = spc.octrees, spc.features\n",
    "point_hierarchy, pyramid, prefix = spc.point_hierarchies, spc.pyramids[0], spc.exsum"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define functions for ray generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _normalized_grid(width, height, device='cuda'):\n",
    "    \"\"\"Returns grid[x,y] -> coordinates for a normalized window.\n",
    "    \n",
    "    Args:\n",
    "        width, height (int): grid resolution\n",
    "    \"\"\"\n",
    "\n",
    "    # These are normalized coordinates\n",
    "    # i.e. equivalent to 2.0 * (fragCoord / iResolution.xy) - 1.0\n",
    "    window_x = torch.linspace(-1, 1, steps=width, device=device) * (width / height)\n",
    "    window_y = torch.linspace(1,- 1, steps=height, device=device)\n",
    "\n",
    "    coord = torch.stack(torch.meshgrid(window_x, window_y)).permute(1,2,0)\n",
    "    return coord\n",
    "\n",
    "\n",
    "def generate_rays(camera_from, camera_to, width, height, mode='persp', fov=90.0, device='cuda'):\n",
    "    \"\"\"Vectorized look-at function, returns an array of ray origins and directions\n",
    "    URL: https://www.scratchapixel.com/lessons/mathematics-physics-for-computer-graphics/lookat-function\n",
    "    \"\"\"\n",
    "\n",
    "    camera_origin = torch.FloatTensor(camera_from).to(device)\n",
    "    camera_view = F.normalize(torch.FloatTensor(camera_to).to(device) - camera_origin, dim=0)\n",
    "    camera_right = F.normalize(torch.cross(camera_view, torch.FloatTensor([0,1,0]).to(device)), dim=0)\n",
    "    camera_up = F.normalize(torch.cross(camera_right, camera_view), dim=0)\n",
    "\n",
    "    coord = _normalized_grid(width, height, device=device)\n",
    "    ray_origin = camera_right * coord[...,0,np.newaxis] * np.tan(np.radians(fov/2)) + \\\n",
    "                 camera_up * coord[...,1,np.newaxis] * np.tan(np.radians(fov/2)) + \\\n",
    "                 camera_origin + camera_view\n",
    "    ray_origin = ray_origin.reshape(-1, 3)\n",
    "    ray_offset = camera_view.unsqueeze(0).repeat(ray_origin.shape[0], 1)\n",
    "    \n",
    "    if mode == 'ortho': # Orthographic camera\n",
    "        ray_dir = F.normalize(ray_offset, dim=-1)\n",
    "    elif mode == 'persp': # Perspective camera\n",
    "        ray_dir = F.normalize(ray_origin - camera_origin, dim=-1)\n",
    "        ray_origin = camera_origin.repeat(ray_dir.shape[0], 1)\n",
    "    else:\n",
    "        raise ValueError('Invalid camera mode!')\n",
    "\n",
    "\n",
    "    return ray_origin, ray_dir\n",
    "\n",
    "def build_ray_at(pixel, eye, up, look_at, right, fov, width, height, show=False, col='red'):    \n",
    "    aspect_ratio = width / height\n",
    "    u = (pixel[1] + 0.5) / width\n",
    "    v = 1. - (pixel[0] + 0.5) / height\n",
    "    w = 2. * np.tan(fov / 2.)\n",
    "    rayDirection = look_at + ((u-0.5) * aspect_ratio * w) * right - ((0.5 - v) * w) * up\n",
    "    \n",
    "    rayDirection = rayDirection / torch.norm(rayDirection)\n",
    "    if (show):\n",
    "        p.add_lines(eye.unsqueeze(0).cpu().numpy(), (eye + 3.*rayDirection).unsqueeze(0).cpu().numpy(), shading={'line_color':col})\n",
    "    return eye, rayDirection\n",
    "\n",
    "def generate_rays_bb(bbox, elev, azim, r):\n",
    "    ray_o = []\n",
    "    ray_d = []\n",
    "    eye, look_at, up, right = get_camera_properties(elev, azim, r)\n",
    "    (startX, startY) , (endX, endY) = (bbox[0], bbox[1])\n",
    "    for row in range(startY, endY):\n",
    "        for col in range(startX, endX):\n",
    "            pixel = (row, col)\n",
    "            rayOrigin, rayDirection = build_ray_at(pixel, eye, up, look_at, right, fov, width=1024, height=1024)\n",
    "            ray_o.append(rayOrigin.cpu().numpy())\n",
    "            ray_d.append(rayDirection.cpu().numpy())\n",
    "    ray_o = torch.tensor(np.array(ray_o), device=device)\n",
    "    ray_d = torch.tensor(np.array(ray_d), device=device)\n",
    "    return ray_o, ray_d\n",
    "\n",
    "def generate_rays_BB(bbox, elev, azim, r, factor):\n",
    "    aspect_ratio = width / height\n",
    "    eye, look_at, up, right = get_camera_properties(elev, azim, r)\n",
    "    (startX, startY) , (endX, endY) = (bbox[0], bbox[1])\n",
    "    u = (torch.linspace(startX, endX - 1, factor*(endX-startX), device=device).unsqueeze(1) + 0.5) / width\n",
    "    v = 1 - (torch.linspace(startY, endY - 1, factor*(endY-startY), device=device).unsqueeze(1) + 0.5) / height\n",
    "    w = 2. * np.tan(fov / 2.)\n",
    "    ray_x = ((u-0.5) * aspect_ratio * w) * right.unsqueeze(0)\n",
    "    ray_x = ray_x.unsqueeze(0)\n",
    "    ray_y = ((0.5 - v) * w) * up.unsqueeze(0)\n",
    "    ray_y = ray_y.unsqueeze(1)\n",
    "    ray_directions = look_at + ray_x - ray_y\n",
    "    ray_directions /= torch.norm(ray_directions, dim=2, keepdim=True)\n",
    "    ray_directions = ray_directions.view(-1,3)\n",
    "    ray_origins = eye.clone().unsqueeze(0).repeat((factor**2)*(endX-startX) * (endY-startY), 1)\n",
    "    return ray_origins, ray_directions    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Rays for full image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ray_o and ray_d ~ torch.Tensor (width x height, 3)\n",
    "# represent rays origin and direction vectors\n",
    "# camera_from=[-.5,2.5,-2.5]\n",
    "camera_from = [0.,0.5,2.]\n",
    "camera_to = [0,0.5,0]\n",
    "ray_o, ray_d = generate_rays(\n",
    "                        camera_from=camera_from,\n",
    "                        camera_to=camera_to,\n",
    "                        width=1024,\n",
    "                        height=1024,\n",
    "                        mode='persp',\n",
    "                        fov=60,\n",
    "                        device='cuda')\n",
    "np.random.seed(42)\n",
    "p = mp.plot(point_cloud, shading={'point_size':0.2, 'point_color':'black'}, return_plot=True)\n",
    "p.add_points(ray_o[0].view(1,3).cpu().numpy(), shading={'point_size':0.2, 'point_color':'green'})\n",
    "for i in range(10):\n",
    "    p.add_lines(ray_o[0].view(1,3).cpu().numpy(), (ray_o[0] + 4.*ray_d[np.random.randint(ray_d.shape[0])]).view(1,3).cpu().numpy(), shading={'line_size':0.2, 'line_color':'blue'})\n",
    "plt.show()\n",
    "print(f'Total of {ray_o.shape[0]} rays generated.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Manually define single Ray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ray_o = torch.tensor([[0.,0.5,2.]], device=device)\n",
    "# ray_d = torch.tensor([[0,0.,-1]], device=device)\n",
    "ray_d = torch.tensor([[ 0.0804, -0.2346, -0.9688]], device=device)\n",
    "p = mp.plot(point_cloud, shading={'point_size':0.2, 'point_color':'black'}, return_plot=True)\n",
    "p.add_lines(ray_o.cpu().numpy(), (ray_o + 2.*ray_d).cpu().numpy(), shading={'line_size':0.2, 'line_color':'blue'})\n",
    "p.add_points(ray_o.cpu().numpy(), shading={'point_size':0.2, 'point_color':'green'})\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Rays in BB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ray_o = []\n",
    "ray_d = []\n",
    "elev = torch.deg2rad(torch.tensor(25)).to(device)\n",
    "azim = torch.deg2rad(torch.tensor(90)).to(device)\n",
    "r = 1.5\n",
    "# r = 3.5\n",
    "fov = np.pi / 3.\n",
    "# startX = 310; startY = 280; endX = 350; endY = 350\n",
    "startX = 400; startY = 200; endX = 600; endY = 400\n",
    "bb = [(startX, startY), (endX, endY)]\n",
    "image, face_idx = render_view(elev, azim, r)\n",
    "face_idx = face_idx.squeeze().cpu().numpy()\n",
    "img_to_show = image.copy()\n",
    "ray_o, ray_d = generate_rays_BB(bb, elev, azim, r, 7)\n",
    "print(f'Generated {ray_o.shape[0]} rays')\n",
    "cv2.rectangle(img_to_show, (startX, startY), (endX, endY), [0,0,255], 2)\n",
    "plt.imshow(img_to_show)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ray Trace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nugs_ridx, nugs_pidx, depth = kal.render.spc.unbatched_raytrace(\n",
    "    octree, point_hierarchy, pyramid, prefix, ray_o, ray_d, level)\n",
    "masked_nugs = kal.render.spc.mark_pack_boundaries(nugs_ridx)\n",
    "nugs_ridx = nugs_ridx[masked_nugs]\n",
    "nugs_pidx = nugs_pidx[masked_nugs]\n",
    "ridx = nugs_ridx.long()\n",
    "pidx = nugs_pidx.long() - pyramid[1,level]\n",
    "print(f'Ray Hits: {ridx.shape[0]} out of {ray_o.shape[0]} - {np.round(ridx.shape[0] / ray_o.shape[0], 2) * 100} %')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Show intersection with PC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = np.zeros((point_cloud.shape[0], 3))\n",
    "\n",
    "threshold = -0.8\n",
    "dot_prods = torch.sum(torch.mul(pts_normals[features[pidx]].squeeze(), ray_d[ridx]), dim=1).unsqueeze(1).cpu().numpy()\n",
    "colors[features[pidx].squeeze().cpu().numpy()] = np.where(dot_prods < threshold,\n",
    "                                                           np.array([0,0,255]), np.array([255,0,0]))\n",
    "# colors[features[pidx].squeeze().cpu().numpy()] = np.array([0,0,255])\n",
    "p = mp.plot(point_cloud, c=colors, shading={'point_size':0.1}, return_plot=True)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# p.add_points(ray_o[0].view(1, -1).cpu().numpy(), shading={'point_size':0.1, 'point_color':'green'})\n",
    "# for i in range(20):\n",
    "#     id_p = np.random.randint(ridx.shape[0])\n",
    "#     # p.add_lines(ray_o[0].view(1, -1).cpu().numpy(), \n",
    "#     #             (ray_o[0] + 4*ray_d[ridx[id_p]]).view(1, -1).cpu().numpy(), \n",
    "#     #             shading={'line_color':'blue'})\n",
    "#     m_hit = point_cloud[features[pidx[id_p]]]\n",
    "#     dot_prod = torch.mm(pts_normals[features[pidx[id_p]]], ray_d[ridx[id_p]].unsqueeze(1)).squeeze().item()\n",
    "#     if (dot_prod > 0):\n",
    "#         p.add_points(m_hit.reshape(1, -1), shading={'point_size':0.2, 'point_color':'blue'})\n",
    "#     else:\n",
    "#         p.add_points(m_hit.reshape(1, -1), shading={'point_size':0.2, 'point_color':'red'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test project back BB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "elev = torch.deg2rad(torch.tensor(25)).to(device)\n",
    "azim = torch.deg2rad(torch.tensor(90)).to(device)\n",
    "# elev = torch.deg2rad(torch.tensor(30)).to(device)\n",
    "# azim = torch.deg2rad(torch.tensor(170)).to(device)\n",
    "r = 1.5\n",
    "# r = 1.8\n",
    "fov = np.pi / 3.\n",
    "image, face_idx = render_view(elev, azim, r)\n",
    "face_idx = face_idx.squeeze().cpu().numpy()\n",
    "img_to_show = image.copy()\n",
    "startX = 310; startY = 280; endX = 350; endY = 350\n",
    "# startX = 400; startY = 200; endX = 500; endY = 600\n",
    "# startX = 400; startY = 170; endX = 430; endY = 250\n",
    "bb = [(startX, startY), (endX, endY)]\n",
    "cv2.rectangle(img_to_show, (startX, startY), (endX, endY), [0,0,255], 2)\n",
    "plt.imshow(img_to_show)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "ray_o, ray_d = generate_rays_BB(bb, elev, azim, r, 7)\n",
    "point_hierarchy, pyramid, prefix = spc.point_hierarchies, spc.pyramids[0], spc.exsum\n",
    "nugs_ridx, nugs_pidx, depth = kal.render.spc.unbatched_raytrace(\n",
    "    octree, point_hierarchy, pyramid, prefix, ray_o, ray_d, level)\n",
    "masked_nugs = kal.render.spc.mark_pack_boundaries(nugs_ridx)\n",
    "nugs_ridx = nugs_ridx[masked_nugs]\n",
    "nugs_pidx = nugs_pidx[masked_nugs]\n",
    "ridx = nugs_ridx.long()\n",
    "pidx = nugs_pidx.long() - pyramid[1, level]\n",
    "\n",
    "colors = np.zeros((point_cloud.shape[0], 3))\n",
    "\n",
    "threshold = -0.8\n",
    "dot_prods = torch.sum(torch.mul(pts_normals[features[pidx]].squeeze(), ray_d[ridx]), dim=1).unsqueeze(1).cpu().numpy()\n",
    "colors[features[pidx].squeeze().cpu().numpy()] = np.where(dot_prods < threshold,\n",
    "                                                           np.array([0,0,255]), np.array([255,0,0]))\n",
    "\n",
    "# colors[features[pidx].squeeze().cpu().numpy()] = np.array([0,0,255])\n",
    "p = mp.plot(point_cloud, c=colors, shading={'point_size':0.18}, return_plot=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "elev = torch.deg2rad(torch.tensor(30)).to(device)\n",
    "azim = torch.deg2rad(torch.tensor(170)).to(device)\n",
    "r = 1.8\n",
    "fov = np.pi / 3.\n",
    "image, face_idx = render_view(elev, azim, r)\n",
    "face_idx = face_idx.squeeze().cpu().numpy()\n",
    "img_to_show = image.copy()\n",
    "startX = 400; startY = 200; endX = 500; endY = 600\n",
    "bb = [(startX, startY), (endX, endY)]\n",
    "cv2.rectangle(img_to_show, (startX, startY), (endX, endY), [0,0,255], 2)\n",
    "plt.imshow(img_to_show)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ray_o, ray_d = generate_rays_BB(bb, elev, azim, r, 7)\n",
    "point_hierarchy, pyramid, prefix = spc.point_hierarchies, spc.pyramids[0], spc.exsum\n",
    "nugs_ridx, nugs_pidx, depth = kal.render.spc.unbatched_raytrace(\n",
    "    octree, point_hierarchy, pyramid, prefix, ray_o, ray_d, level)\n",
    "masked_nugs = kal.render.spc.mark_pack_boundaries(nugs_ridx)\n",
    "nugs_ridx = nugs_ridx[masked_nugs]\n",
    "nugs_pidx = nugs_pidx[masked_nugs]\n",
    "ridx = nugs_ridx.long()\n",
    "pidx = nugs_pidx.long() - pyramid[1, level]\n",
    "\n",
    "colors = np.zeros((point_cloud.shape[0], 3))\n",
    "\n",
    "threshold = -0.8\n",
    "dot_prods = torch.sum(torch.mul(pts_normals[features[pidx]].squeeze(), ray_d[ridx]), dim=1).unsqueeze(1).cpu().numpy()\n",
    "\n",
    "colors[features[pidx].squeeze().cpu().numpy()] = np.where(dot_prods < threshold,\n",
    "                                                           np.array([0,0,255]), np.array([0,255,0]))\n",
    "\n",
    "\n",
    "# colors[features[pidx].squeeze().cpu().numpy()] = np.array([0,0,255])\n",
    "p = mp.plot(point_cloud, c=colors, shading={'point_size':0.12}, return_plot=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "elev = torch.deg2rad(torch.tensor(15)).to(device)\n",
    "azim = torch.deg2rad(torch.tensor(270)).to(device)\n",
    "r = 2.\n",
    "fov = np.pi / 3.\n",
    "image, face_idx = render_view(elev, azim, r)\n",
    "face_idx = face_idx.squeeze().cpu().numpy()\n",
    "img_to_show = image.copy()\n",
    "startX = 300; startY = 120; endX = 720; endY = 600\n",
    "bb = [(startX, startY), (endX, endY)]\n",
    "cv2.rectangle(img_to_show, (startX, startY), (endX, endY), [0,0,255], 2)\n",
    "plt.imshow(img_to_show)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ray_o, ray_d = generate_rays_BB(bb, elev, azim, r, 7)\n",
    "point_hierarchy, pyramid, prefix = spc.point_hierarchies, spc.pyramids[0], spc.exsum\n",
    "nugs_ridx, nugs_pidx, depth = kal.render.spc.unbatched_raytrace(\n",
    "    octree, point_hierarchy, pyramid, prefix, ray_o, ray_d, level)\n",
    "masked_nugs = kal.render.spc.mark_pack_boundaries(nugs_ridx)\n",
    "nugs_ridx = nugs_ridx[masked_nugs]\n",
    "nugs_pidx = nugs_pidx[masked_nugs]\n",
    "ridx = nugs_ridx.long()\n",
    "pidx = nugs_pidx.long() - pyramid[1, level]\n",
    "\n",
    "colors = np.zeros((point_cloud.shape[0], 3))\n",
    "\n",
    "threshold = -0.8\n",
    "dot_prods = torch.sum(torch.mul(pts_normals[features[pidx]].squeeze(), ray_d[ridx]), dim=1).unsqueeze(1).cpu().numpy()\n",
    "colors[features[pidx].squeeze().cpu().numpy()] = np.where(dot_prods < threshold,\n",
    "                                                           np.array([0,0,255]), np.array([255,0,0]))\n",
    "\n",
    "# colors[features[pidx].squeeze().cpu().numpy()] = np.array([0,0,255])\n",
    "p = mp.plot(point_cloud, c=colors, shading={'point_size':0.15}, return_plot=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "elev = torch.deg2rad(torch.tensor(15)).to(device)\n",
    "azim = torch.deg2rad(torch.tensor(70)).to(device)\n",
    "image, face_idx = render_view(elev, azim, 2)\n",
    "face_idx = face_idx.squeeze().cpu().numpy()\n",
    "img_to_show = image.copy()\n",
    "startX = 310; startY = 535; endX = 720; endY = 600\n",
    "bb = [(startX, startY), (endX, endY)]\n",
    "cv2.rectangle(img_to_show, (startX, startY), (endX, endY), [0,0,255], 2)\n",
    "plt.imshow(img_to_show)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ray_o, ray_d = generate_rays_BB(bb, elev, azim, r, 7)\n",
    "point_hierarchy, pyramid, prefix = spc.point_hierarchies, spc.pyramids[0], spc.exsum\n",
    "nugs_ridx, nugs_pidx, depth = kal.render.spc.unbatched_raytrace(\n",
    "    octree, point_hierarchy, pyramid, prefix, ray_o, ray_d, level)\n",
    "masked_nugs = kal.render.spc.mark_pack_boundaries(nugs_ridx)\n",
    "nugs_ridx = nugs_ridx[masked_nugs]\n",
    "nugs_pidx = nugs_pidx[masked_nugs]\n",
    "ridx = nugs_ridx.long()\n",
    "pidx = nugs_pidx.long() - pyramid[1,level]\n",
    "\n",
    "colors = np.zeros((point_cloud.shape[0], 3))\n",
    "\n",
    "threshold = -0.8\n",
    "dot_prods = torch.sum(torch.mul(pts_normals[features[pidx]].squeeze(), ray_d[ridx]), dim=1).unsqueeze(1).cpu().numpy()\n",
    "colors[features[pidx].squeeze().cpu().numpy()] = np.where(dot_prods < threshold,\n",
    "                                                           np.array([0,0,255]), np.array([255,0,0]))\n",
    "\n",
    "# colors[features[pidx].squeeze().cpu().numpy()] = np.array([0,0,255])\n",
    "p = mp.plot(point_cloud, c=colors, shading={'point_size':0.1}, return_plot=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "elev = torch.deg2rad(torch.tensor(40)).to(device)\n",
    "azim = torch.deg2rad(torch.tensor(130)).to(device)\n",
    "image, face_idx = render_view(elev, azim, 2)\n",
    "face_idx = face_idx.squeeze().cpu().numpy()\n",
    "img_to_show = image.copy()\n",
    "startX = 250; startY = 150; endX = 720; endY = 640\n",
    "bb = [(startX, startY), (endX, endY)]\n",
    "cv2.rectangle(img_to_show, (startX, startY), (endX, endY), [0,0,255], 2)\n",
    "plt.imshow(img_to_show)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ray_o, ray_d = generate_rays_BB(bb, elev, azim, r, 7)\n",
    "point_hierarchy, pyramid, prefix = spc.point_hierarchies, spc.pyramids[0], spc.exsum\n",
    "nugs_ridx, nugs_pidx, depth = kal.render.spc.unbatched_raytrace(\n",
    "    octree, point_hierarchy, pyramid, prefix, ray_o, ray_d, level)\n",
    "masked_nugs = kal.render.spc.mark_pack_boundaries(nugs_ridx)\n",
    "nugs_ridx = nugs_ridx[masked_nugs]\n",
    "nugs_pidx = nugs_pidx[masked_nugs]\n",
    "ridx = nugs_ridx.long()\n",
    "pidx = nugs_pidx.long() - pyramid[1,level]\n",
    "\n",
    "colors = np.zeros((point_cloud.shape[0], 3))\n",
    "\n",
    "threshold = -0.4\n",
    "dot_prods = torch.sum(torch.mul(pts_normals[features[pidx]].squeeze(), ray_d[ridx]), dim=1).unsqueeze(1).cpu().numpy()\n",
    "colors[features[pidx].squeeze().cpu().numpy()] = np.where(dot_prods < threshold,\n",
    "                                                           np.array([0,0,255]), np.array([255,0,0]))\n",
    "\n",
    "# colors[features[pidx].squeeze().cpu().numpy()] = np.array([0,0,255])\n",
    "p = mp.plot(point_cloud, c=colors, shading={'point_size':0.15}, return_plot=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sample double the number of points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = int(vertices.shape[0] * 2)\n",
    "point_cloud, pt_to_face = trimesh.sample.sample_surface_even(trimeshMesh, N)\n",
    "torchPC = torch.tensor(point_cloud, device=torch.device('cuda:0'), dtype=torch.float32)\n",
    "# Our SPC will contain a hierarchy of multiple levels\n",
    "level = 8\n",
    "torch.manual_seed(0)\n",
    "# colors = torch.rand(point_cloud.shape[0], 3, device=device)\n",
    "# colors = torch.tensor(point_cloud, device=device)\n",
    "# colors = torch.tensor(point_cloud[:,:1]).to(device)\n",
    "colors = torch.arange(0, point_cloud.shape[0]).unsqueeze(1).to(device)\n",
    "# mp.plot(point_cloud, c = colors.cpu().numpy(), shading={'point_size':0.2})\n",
    "# plt.show()\n",
    "spc = kal.ops.conversions.pointcloud.unbatched_pointcloud_to_spc(\n",
    "    pointcloud=torchPC, level=level, features=colors)\n",
    "octree, features = spc.octrees, spc.features\n",
    "point_hierarchy, pyramid, prefix = spc.point_hierarchies, spc.pyramids[0], spc.exsum\n",
    "elev = torch.deg2rad(torch.tensor(25)).to(device)\n",
    "azim = torch.deg2rad(torch.tensor(90)).to(device)\n",
    "r = 1.5\n",
    "fov = np.pi / 3.\n",
    "image, face_idx = render_view(elev, azim, r)\n",
    "face_idx = face_idx.squeeze().cpu().numpy()\n",
    "img_to_show = image.copy()\n",
    "startX = 310; startY = 280; endX = 350; endY = 350\n",
    "# startX = 400; startY = 170; endX = 430; endY = 250\n",
    "bb = [(startX, startY), (endX, endY)]\n",
    "cv2.rectangle(img_to_show, (startX, startY), (endX, endY), [0,0,255], 2)\n",
    "plt.imshow(img_to_show)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ray_o, ray_d = generate_rays_BB(bb, elev, azim, r, 7)\n",
    "point_hierarchy, pyramid, prefix = spc.point_hierarchies, spc.pyramids[0], spc.exsum\n",
    "nugs_ridx, nugs_pidx, depth = kal.render.spc.unbatched_raytrace(\n",
    "    octree, point_hierarchy, pyramid, prefix, ray_o, ray_d, level)\n",
    "masked_nugs = kal.render.spc.mark_pack_boundaries(nugs_ridx)\n",
    "nugs_ridx = nugs_ridx[masked_nugs]\n",
    "nugs_pidx = nugs_pidx[masked_nugs]\n",
    "ridx = nugs_ridx.long()\n",
    "pidx = nugs_pidx.long() - pyramid[1,level]\n",
    "\n",
    "colors = np.zeros((point_cloud.shape[0], 3))\n",
    "colors[features[pidx].squeeze().cpu().numpy()] = np.array([0,0,255])\n",
    "p = mp.plot(point_cloud, c=colors, shading={'point_size':0.08}, return_plot=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "elev = torch.deg2rad(torch.tensor(40)).to(device)\n",
    "azim = torch.deg2rad(torch.tensor(160)).to(device)\n",
    "image, face_idx = render_view(elev, azim, 2)\n",
    "face_idx = face_idx.squeeze().cpu().numpy()\n",
    "img_to_show = image.copy()\n",
    "startX = 320; startY = 100; endX = 500; endY = 640\n",
    "bb = [(startX, startY), (endX, endY)]\n",
    "cv2.rectangle(img_to_show, (startX, startY), (endX, endY), [0,0,255], 2)\n",
    "plt.imshow(img_to_show)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ray_o, ray_d = generate_rays_BB(bb, elev, azim, r, 10)\n",
    "point_hierarchy, pyramid, prefix = spc.point_hierarchies, spc.pyramids[0], spc.exsum\n",
    "nugs_ridx, nugs_pidx, depth = kal.render.spc.unbatched_raytrace(\n",
    "    octree, point_hierarchy, pyramid, prefix, ray_o, ray_d, level)\n",
    "masked_nugs = kal.render.spc.mark_pack_boundaries(nugs_ridx)\n",
    "nugs_ridx = nugs_ridx[masked_nugs]\n",
    "nugs_pidx = nugs_pidx[masked_nugs]\n",
    "ridx = nugs_ridx.long()\n",
    "pidx = nugs_pidx.long() - pyramid[1,level]\n",
    "\n",
    "colors = np.zeros((point_cloud.shape[0], 3))\n",
    "\n",
    "threshold = 0.0\n",
    "dot_prods = torch.abs(torch.sum(torch.mul(pts_normals[features[pidx]].squeeze(), ray_d[ridx]), dim=1)).unsqueeze(1).cpu().numpy()\n",
    "dot_prods[dot_prods < threshold] = 0.\n",
    "dot_prods[dot_prods > threshold] = 255.\n",
    "colors[features[pidx].squeeze().cpu().numpy()] = np.hstack((np.zeros((dot_prods.shape[0], 2)), dot_prods))\n",
    "\n",
    "# colors[features[pidx].squeeze().cpu().numpy()] = np.array([0,0,255])\n",
    "p = mp.plot(point_cloud, c=colors, shading={'point_size':0.1}, return_plot=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bed Mesh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "object = 'bed' \n",
    "obj_path = 'data/demo/' + object + '.obj'\n",
    "\n",
    "# Read mesh\n",
    "mesh = kal.io.obj.import_mesh(\n",
    "    obj_path,\n",
    "    with_normals=True,\n",
    "    with_materials=False,\n",
    ")\n",
    "\n",
    "vertices_tensor = mesh.vertices.to(device)\n",
    "faces_tensor = mesh.faces.to(device)\n",
    "\n",
    "vertices = vertices_tensor.detach().cpu().numpy()\n",
    "faces = faces_tensor.detach().cpu().numpy()\n",
    "colors =  mesh.vertex_normals.cpu().numpy()\n",
    "\n",
    "trimeshMesh = trimesh.Trimesh(vertices, faces)\n",
    "N = int(vertices.shape[0] * 2)\n",
    "# N = int(vertices.shape[0] / 2)\n",
    "point_cloud, pt_to_face = trimesh.sample.sample_surface_even(trimeshMesh, N)\n",
    "torchPC = torch.tensor(point_cloud, device=torch.device('cuda:0'), dtype=torch.float32)\n",
    "face_to_all_pts = defaultdict(list)\n",
    "for pt in range(len(point_cloud)):\n",
    "    face_to_all_pts[pt_to_face[pt]].append(pt)\n",
    "\n",
    "def computeNormals(mesh, pt_to_face):\n",
    "    face_normals = kal.ops.mesh.face_normals(\n",
    "        kal.ops.mesh.index_vertices_by_faces(mesh.vertices.unsqueeze(0), mesh.faces), unit=True).squeeze()\n",
    "    n_pts = len(pt_to_face)\n",
    "    mp.plot(vertices, faces, face_normals.cpu().numpy())\n",
    "    plt.show()\n",
    "    pts_normals = torch.zeros((n_pts, 3), device = device)\n",
    "    for pt in range(n_pts):\n",
    "        pts_normals[pt] = face_normals[pt_to_face[pt]]\n",
    "    return pts_normals\n",
    "\n",
    "pts_normals = computeNormals(mesh, pt_to_face)\n",
    "# mp.plot(point_cloud, c = pts_normals.cpu().numpy(), shading={'point_size':0.15})\n",
    "# plt.show()\n",
    "# Our SPC will contain a hierarchy of multiple levels\n",
    "level = 7\n",
    "torch.manual_seed(0)\n",
    "colors = torch.arange(0, point_cloud.shape[0]).unsqueeze(1).to(device)\n",
    "spc = kal.ops.conversions.pointcloud.unbatched_pointcloud_to_spc(\n",
    "    pointcloud=torchPC, level=level, features=colors)\n",
    "octree, features = spc.octrees, spc.features\n",
    "point_hierarchy, pyramid, prefix = spc.point_hierarchies, spc.pyramids[0], spc.exsum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "elev = torch.deg2rad(torch.tensor(40)).to(device)\n",
    "azim = torch.deg2rad(torch.tensor(90)).to(device)\n",
    "r = 4.\n",
    "fov = np.pi / 3.\n",
    "image, face_idx = render_view(elev, azim, r)\n",
    "face_idx = face_idx.squeeze().cpu().numpy()\n",
    "img_to_show = image.copy()\n",
    "# startX = 300; startY = 170; endX = 720; endY = 310\n",
    "startX = 280; startY = 310; endX = 740; endY = 700\n",
    "bb = [(startX, startY), (endX, endY)]\n",
    "cv2.rectangle(img_to_show, (startX, startY), (endX, endY), [0,0,255], 2)\n",
    "plt.imshow(img_to_show)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ray_o, ray_d = generate_rays_BB(bb, elev, azim, r, 7)\n",
    "print(f'Generated {ray_o.shape[0]} rays')\n",
    "point_hierarchy, pyramid, prefix = spc.point_hierarchies, spc.pyramids[0], spc.exsum\n",
    "nugs_ridx, nugs_pidx, depth = kal.render.spc.unbatched_raytrace(\n",
    "    octree, point_hierarchy, pyramid, prefix, ray_o, ray_d, level)\n",
    "masked_nugs = kal.render.spc.mark_pack_boundaries(nugs_ridx)\n",
    "nugs_ridx = nugs_ridx[masked_nugs]\n",
    "nugs_pidx = nugs_pidx[masked_nugs]\n",
    "ridx = nugs_ridx.long()\n",
    "pidx = nugs_pidx.long() - pyramid[1, level]\n",
    "print(f'Ray Hits: {ridx.shape[0]} out of {ray_o.shape[0]} - {np.round(ridx.shape[0] / ray_o.shape[0], 2) * 100} %')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = np.zeros((point_cloud.shape[0], 3))\n",
    "\n",
    "threshold = 0.\n",
    "dot_prods = torch.abs(torch.sum(torch.mul(pts_normals[features[pidx]].squeeze(), ray_d[ridx]), dim=1)).unsqueeze(1).cpu().numpy()\n",
    "dot_prods[dot_prods < threshold] = 0.\n",
    "# dot_prods[dot_prods > threshold] = 255.\n",
    "colors[features[pidx].squeeze().cpu().numpy()] = np.hstack((np.zeros((dot_prods.shape[0], 2)), dot_prods))\n",
    "\n",
    "# dot_prods = 0.5 + 0.5*dot_prods\n",
    "# colors[features[pidx].squeeze().cpu().numpy()] = np.hstack((dot_prods, np.zeros((dot_prods.shape[0], 2))))\n",
    "# colors[features[pidx].squeeze().cpu().numpy()] = np.array([0,0,255])\n",
    "p = mp.plot(point_cloud, c=colors, shading={'point_size':0.12}, return_plot=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "relevant_pts = point_cloud[features[pidx].squeeze().unique().cpu().numpy()].reshape(-1,3)\n",
    "x_id = np.argmax(relevant_pts[:, 2])\n",
    "p = mp.plot(point_cloud, shading={'point_size':0.07, 'point_color':'black'}, return_plot=True)\n",
    "p.add_points(relevant_pts, shading={'point_size':0.1, 'point_color':'red'})\n",
    "p.add_points(relevant_pts[x_id].reshape(-1,3)\n",
    "             , shading={'point_size':0.3, 'point_color':'blue'})\n",
    "print()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "test_proj",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
