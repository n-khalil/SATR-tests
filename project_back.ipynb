{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports and set torch device\n",
    "import numpy as np\n",
    "import meshplot as mp\n",
    "import matplotlib.pyplot as plt\n",
    "import kaolin as kal\n",
    "import cv2\n",
    "from collections import defaultdict\n",
    "import trimesh\n",
    "from scipy.spatial.distance import cdist\n",
    "import torch\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda:0\")\n",
    "    torch.cuda.set_device(device)\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "\n",
    "print('Torch will run on:', device)\n",
    "\n",
    "object = 'bookshelf' \n",
    "obj_path = 'data/demo/' + object + '.obj'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read Mesh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read mesh\n",
    "mesh = kal.io.obj.import_mesh(\n",
    "    obj_path,\n",
    "    with_normals=True,\n",
    "    with_materials=False,\n",
    ")\n",
    "\n",
    "vertices_tensor = mesh.vertices.to(device)\n",
    "faces_tensor = mesh.faces.to(device)\n",
    "\n",
    "vertices = vertices_tensor.detach().cpu().numpy()\n",
    "faces = faces_tensor.detach().cpu().numpy()\n",
    "colors =  mesh.vertex_normals.cpu().numpy()\n",
    "\n",
    "print('Number of vertices: ', vertices.shape[0])\n",
    "print('Number of faces: ', faces.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sample Points on mesh surface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize mesh\n",
    "trimeshMesh = trimesh.Trimesh(vertices, faces)\n",
    "# N = int(vertices.shape[0] * 2)\n",
    "N = int(vertices.shape[0] / 2)\n",
    "point_cloud, pt_to_face = trimesh.sample.sample_surface_even(trimeshMesh, N)\n",
    "torchPC = torch.tensor(point_cloud, device=torch.device('cuda:0'), dtype=torch.float32)\n",
    "face_to_all_pts = defaultdict(list)\n",
    "for pt in range(len(point_cloud)):\n",
    "    face_to_all_pts[pt_to_face[pt]].append(pt)\n",
    "p = mp.plot(vertices, faces, colors, return_plot=True, shading={\"wireframe\": 0.1})\n",
    "p.add_points(point_cloud, shading={\"point_size\": 0.1, \"point_color\": \"green\"})\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define rendering functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_camera_from_view2(elev, azim, r=3.0):\n",
    "    x = r * torch.cos(elev) * torch.cos(azim)\n",
    "    y = r * torch.sin(elev)\n",
    "    z = r * torch.cos(elev) * torch.sin(azim)\n",
    "    pos = torch.tensor([x, y, z]).unsqueeze(0)\n",
    "    look_at = - pos\n",
    "    direction = torch.tensor([0.0, 1.0, 0.0]).unsqueeze(0)\n",
    "    camera_proj = kal.render.camera.generate_transformation_matrix(pos, look_at, direction)\n",
    "    return camera_proj\n",
    "\n",
    "\n",
    "def render_view(elev, azim, r):\n",
    "    background = torch.tensor([255.0, 255.0, 255.0]).to(device)\n",
    "    # face_attributes = kal.ops.mesh.index_vertices_by_faces(\n",
    "    #     torch.ones(1, len(mesh.vertices), 3).to(device)\n",
    "    #     * torch.tensor([0.5, 0.5, 0.5]).unsqueeze(0).unsqueeze(0).to(device),\n",
    "    #     faces_tensor,\n",
    "    # )\n",
    "    face_attributes = kal.ops.mesh.index_vertices_by_faces(\n",
    "            mesh.vertex_normals.unsqueeze(0).to(device),\n",
    "            faces_tensor\n",
    "    ) \n",
    "    face_attributes = [\n",
    "        face_attributes,  # Colors\n",
    "        torch.ones((1, faces.shape[0], 3, 1), device=device),  # hard seg. mask\n",
    "    ]\n",
    "    \n",
    "    camera_projection = kal.render.camera.generate_perspective_projection(np.pi / 3).to(device)\n",
    "    camera_transform = get_camera_from_view2(elev, azim, r=r).to(device)\n",
    "    (\n",
    "        face_vertices_camera,\n",
    "        face_vertices_image,\n",
    "        face_normals,\n",
    "    ) = kal.render.mesh.prepare_vertices(\n",
    "        mesh.vertices.to(device),\n",
    "        mesh.faces.to(device),\n",
    "        camera_projection,\n",
    "        camera_transform=camera_transform,\n",
    "    )\n",
    "\n",
    "    # v = mesh.vertices[faces[0, 0]].to(device).unsqueeze(0)\n",
    "    # v = torch.cat((v, torch.tensor([[1]], device=device)), 1)\n",
    "    # print(face_vertices_camera.squeeze()[0, 0].unsqueeze(0))\n",
    "    # print(torch.mm(v, camera_transform.squeeze()))\n",
    "    # print(face_vertices_image[0,0,0])\n",
    "\n",
    "    image_features, soft_mask, face_idx = kal.render.mesh.dibr_rasterization(\n",
    "        1024,\n",
    "        1024,\n",
    "        face_vertices_camera[:, :, :, -1],\n",
    "        face_vertices_image,\n",
    "        face_attributes,\n",
    "        face_normals[:, :, -1],\n",
    "    )\n",
    "\n",
    "    image_features, mask = image_features\n",
    "    image = torch.clamp(image_features, 0.0, 1.0)\n",
    "    lights=torch.tensor([1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0]).unsqueeze(0).to(device)\n",
    "    image_normals = face_normals[:, face_idx].squeeze(0)\n",
    "    image_lighting = kal.render.mesh.spherical_harmonic_lighting(\n",
    "        image_normals, lights\n",
    "        ).unsqueeze(0)\n",
    "    image = image * image_lighting.repeat(1, 3, 1, 1).permute(\n",
    "        0, 2, 3, 1\n",
    "        ).to(device)\n",
    "    image = torch.clamp(image, 0.0, 1.0)\n",
    "    background_mask = torch.zeros(image.shape).to(device)\n",
    "    mask = mask.squeeze(-1)\n",
    "    background_idx = torch.where(mask == 0)\n",
    "    assert torch.all(\n",
    "        image[background_idx] == torch.zeros(3).to(device)\n",
    "    )  # Remvoe it may be taking a lot of time\n",
    "    background_mask[\n",
    "        background_idx\n",
    "    ] = background  # .repeat(background_idx[0].shape)\n",
    "    image = torch.clamp(image + background_mask, 0.0, 1.0)\n",
    "    image = image.squeeze().cpu().numpy()\n",
    "    image *= 255.0\n",
    "    image = image.astype(np.uint8)\n",
    "    return image, face_idx\n",
    "\n",
    "from SAM import SamPredictor, sam_model_registry\n",
    "sam = sam_model_registry[\"vit_h\"](checkpoint=\"./SAM/MODEL/sam_vit_h_4b8939.pth\")\n",
    "predictor = SamPredictor(sam)\n",
    "def show_mask(mask, ax, random_color=False):\n",
    "    if random_color:\n",
    "        color = np.concatenate([np.random.random(3), np.array([0.6])], axis=0)\n",
    "    else:\n",
    "        color = np.array([30/255, 144/255, 255/255, 0.6])\n",
    "    h, w = mask.shape[-2:]\n",
    "    mask_image = mask.reshape(h, w, 1) * color.reshape(1, 1, -1)\n",
    "    ax.imshow(mask_image)\n",
    "    \n",
    "def show_points(coords, labels, ax, marker_size=375):\n",
    "    pos_points = coords[labels==1]\n",
    "    neg_points = coords[labels==0]\n",
    "    ax.scatter(pos_points[:, 0], pos_points[:, 1], color='green', marker='*', s=marker_size, edgecolor='white', linewidth=1.25)\n",
    "    ax.scatter(neg_points[:, 0], neg_points[:, 1], color='red', marker='*', s=marker_size, edgecolor='white', linewidth=1.25)   \n",
    "    \n",
    "def show_box(box, ax):\n",
    "    x0, y0 = box[0], box[1]\n",
    "    w, h = box[2] - box[0], box[3] - box[1]\n",
    "    ax.add_patch(plt.Rectangle((x0, y0), w, h, edgecolor='green', facecolor=(0,0,0,0), lw=2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Project one pixel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_camera_properties(elev, azim, r):\n",
    "    x = r * torch.cos(elev) * torch.cos(azim)\n",
    "    y = r * torch.sin(elev)\n",
    "    z = r * torch.cos(elev) * torch.sin(azim)\n",
    "    eye = torch.tensor([x, y, z], device=device)\n",
    "    look_at = - eye\n",
    "    look_at /= torch.norm(look_at)\n",
    "    up = torch.tensor([0.0, 1.0, 0.0], device=device)\n",
    "    right = torch.cross(look_at, up)\n",
    "    right /= torch.norm(right)\n",
    "    up = torch.cross(right, look_at)\n",
    "    up /= torch.norm(up)\n",
    "    return eye, look_at, up, right\n",
    "\n",
    "def project_pixel(pixel, point_cloud, width, height, eye, up, look_at, right, fov, face_id):\n",
    "    # eye, look_at, upVector = get_camera_properties(elev, azim, r)\n",
    "    # ray = build_ray_at((0,0), eye, upVector, look_at, fov, width, height, col='blue')\n",
    "    # ray = build_ray_at((width, 0), eye, upVector, look_at, fov, width, height, col='blue')\n",
    "    # ray = build_ray_at((0, height), eye, upVector, look_at, fov, width, height, col='blue')\n",
    "    # ray = build_ray_at((width, height), eye, upVector, look_at, fov, width, height, col='blue')\n",
    "    ray = build_ray_at(pixel, eye, up, look_at, right, fov, width, height)\n",
    "    # print(f'Ray info:\\nEye: {eye}\\nDirection: {ray.direction}')\n",
    "    triangle = mesh.vertices[mesh.faces[face_id]].to(device)\n",
    "    intersection = ray.ray_triangle_intersection(triangle)\n",
    "    # p.add_points(intersection.view(-1, 3).cpu().numpy(), shading={'point_size':0.28, 'point_color':'orange'})\n",
    "    pt = closest_point(point_cloud, intersection, face_id)\n",
    "    return pt   \n",
    "\n",
    "def build_ray_at(pixel, eye, up, look_at, right, fov, width, height, show=False, col='red'):    \n",
    "    aspect_ratio = width / height\n",
    "    u = (pixel[1] + 0.5) / width\n",
    "    v = 1. - (pixel[0] + 0.5) / height\n",
    "    w = 2. * np.tan(fov / 2.)\n",
    "    rayDirection = look_at + ((u-0.5) * aspect_ratio * w) * right - ((0.5 - v) * w) * up\n",
    "    \n",
    "    rayDirection = rayDirection / torch.norm(rayDirection)\n",
    "    # p.add_points(eye.unsqueeze(0).cpu().numpy(), shading={'point_size':0.25, 'point_color':'green'})\n",
    "    # p.add_lines(eye.unsqueeze(0).cpu().numpy(), (eye + 0.6*look_at).unsqueeze(0).cpu().numpy(), shading={'line_color':'black'})\n",
    "    # p.add_lines(eye.unsqueeze(0).cpu().numpy(), (eye + 0.6*up).unsqueeze(0).cpu().numpy(), shading={'line_color':'black'})\n",
    "    # p.add_lines(eye.unsqueeze(0).cpu().numpy(), (eye + 0.6*right).unsqueeze(0).cpu().numpy(), shading={'line_color':'black'})\n",
    "    if (show):\n",
    "        p.add_lines(eye.unsqueeze(0).cpu().numpy(), (eye + 3.*rayDirection).unsqueeze(0).cpu().numpy(), shading={'line_color':col})\n",
    "    ray = Ray(eye, rayDirection, torch.device(\"cuda:0\"))\n",
    "    return ray\n",
    "\n",
    "def closest_point(point_cloud, src_point, face_id):\n",
    "    # distances = cdist(point_cloud.view(-1, 3).cpu().numpy(), src_point.view(-1, 3).cpu().numpy())\n",
    "    if (len(face_to_all_pts[face_id]) != 0):\n",
    "        pts_lst = face_to_all_pts[face_id]\n",
    "        distances = cdist(\n",
    "                        point_cloud[pts_lst].view(-1, 3).cpu().numpy(),\n",
    "                        src_point.view(-1, 3).cpu().numpy()\n",
    "                        )\n",
    "        # print(f'Face_id: {face_id}')\n",
    "        # print(f'face to pts [face_id]: {len(pts_lst)}')\n",
    "        # print(f'Dist: {distances.shape}')\n",
    "        # print(f'Argmin: {np.argmin(distances)}')\n",
    "        # print(f'Returning: {face_to_all_pts[np.argmin(distances)]}')\n",
    "        # return face_to_all_pts[np.argmin(distances)]\n",
    "        return pts_lst[np.argmin(distances)]\n",
    "    else:\n",
    "        distances = cdist(\n",
    "            point_cloud.view(-1, 3).cpu().numpy(),\n",
    "            src_point.view(-1, 3).cpu().numpy()\n",
    "        )    \n",
    "        return np.argmin(distances)\n",
    "\n",
    "class Ray():\n",
    "    def __init__(self, origin, direction, device):\n",
    "        self.origin = origin.to(device)\n",
    "        self.direction = direction.to(device)\n",
    "        self.device = device\n",
    "    def ray_parametric(self, t):\n",
    "        return self.origin + t * self.direction    \n",
    "    def ray_triangle_intersection(self, triangle):\n",
    "        p0 = triangle[0]\n",
    "        p1 = triangle[1]\n",
    "        p2 = triangle[2]\n",
    "        e1 = p1 - p0\n",
    "        e2 = p2 - p0\n",
    "        dxe2 = torch.cross(self.direction, e2)\n",
    "        det = torch.dot(e1, dxe2)\n",
    "        invDet = 1. / det\n",
    "        op0 = self.origin - p0\n",
    "        u = torch.dot(op0, dxe2) * invDet\n",
    "        op0xe1 = torch.cross(op0, e1)\n",
    "        v = torch.dot(self.direction, op0xe1)\n",
    "        t = torch.dot(e2, op0xe1) * invDet\n",
    "        return self.ray_parametric(t)\n",
    "    def __str__(self):\n",
    "        return f'Origin:\\n{self.origin}\\nDirection:\\n{self.direction}'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test projecting one pixel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# elev = torch.deg2rad(torch.tensor(45)).to(device)\n",
    "# azim = torch.deg2rad(torch.tensor(25)).to(device)\n",
    "elev = torch.deg2rad(torch.tensor(25)).to(device)\n",
    "azim = torch.deg2rad(torch.tensor(90)).to(device)\n",
    "# r = 1.3\n",
    "r = 1.5\n",
    "eye, look_at, up, right = get_camera_properties(elev, azim, r)\n",
    "print(f'Camera parameters: {eye, look_at, up}')\n",
    "image, face_idx = render_view(elev, azim, r)\n",
    "face_idx = face_idx.squeeze()\n",
    "# pixel = (650, 570)\n",
    "pixel = (297, 310)\n",
    "face_id = face_idx[pixel[0], pixel[1]].item()\n",
    "p = mp.plot(point_cloud, shading={'point_size':0.1, 'point_color':'black'}, return_plot=True)\n",
    "# p.add_mesh(vertices, faces)\n",
    "\n",
    "pt = project_pixel(pixel, torch.tensor(point_cloud, \n",
    "                device=torch.device('cuda:0'),\n",
    "                dtype=torch.float32), 1024, 1024, eye, up, look_at, right, np.pi/3., face_id)\n",
    "print(f'pt: {pt}')\n",
    "image[pixel[0]-10:pixel[0]+10, pixel[1]-10:pixel[1]+10] = np.array([255,0,0])\n",
    "plt.imshow(image)\n",
    "plt.show()\n",
    "p.add_points(point_cloud[pt].reshape(1, -1), shading={'point_size':0.35, 'point_color':'blue'})\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Project back BB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def project_back_bb(bbox, width, height, point_cloud, elev, azim, r, fov, face_idx, p):\n",
    "    (startX, startY) , (endX, endY) = (bbox[0], bbox[1])\n",
    "    pts_colors = np.zeros((point_cloud.shape[0], 3))\n",
    "    eye, look_at, up, right = get_camera_properties(elev, azim, r)\n",
    "    torchPC = torch.tensor(point_cloud, device=torch.device('cuda:0'), dtype=torch.float32)\n",
    "    for row in range(startY, endY):\n",
    "        for col in range(startX, endX):\n",
    "            pixel = (row, col)\n",
    "            face_id = face_idx[row, col].item()\n",
    "            if (face_id != -1):\n",
    "                pt = project_pixel(pixel, torchPC, width, height, eye, up, look_at, right, fov, face_id)\n",
    "                pts_colors[pt] = np.array([255,0,0])      \n",
    "    return pts_colors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Projecting back BB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "elev = torch.deg2rad(torch.tensor(25)).to(device)\n",
    "azim = torch.deg2rad(torch.tensor(90)).to(device)\n",
    "r = 2.\n",
    "fov = np.pi / 3.\n",
    "image, face_idx = render_view(elev, azim, r)\n",
    "face_idx = face_idx.squeeze().cpu().numpy()\n",
    "img_to_show = image.copy()\n",
    "startX = 400; startY = 100; endX = 401; endY = 101\n",
    "bb = [(startX, startY), (endX, endY)]\n",
    "cv2.rectangle(img_to_show, (startX, startY), (endX, endY), [255,0,0], 2)\n",
    "plt.imshow(img_to_show)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = project_back_bb(bb, 1024, 1024,point_cloud, elev, azim, r, fov, face_idx, p)\n",
    "p = mp.plot(point_cloud, c = colors, shading = {'point_size':0.18}, return_plot=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "elev = torch.deg2rad(torch.tensor(25)).to(device)\n",
    "azim = torch.deg2rad(torch.tensor(90)).to(device)\n",
    "r = 1.5\n",
    "fov = np.pi / 3.\n",
    "image, face_idx = render_view(elev, azim, r)\n",
    "face_idx = face_idx.squeeze().cpu().numpy()\n",
    "img_to_show = image.copy()\n",
    "startX = 310; startY = 280; endX = 350; endY = 350\n",
    "bb = [(startX, startY), (endX, endY)]\n",
    "cv2.rectangle(img_to_show, (startX, startY), (endX, endY), [255,0,0], 2)\n",
    "plt.imshow(img_to_show)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = project_back_bb(bb, 1024, 1024,point_cloud, elev, azim, r, fov, face_idx, p)\n",
    "p = mp.plot(point_cloud, c = colors, shading = {'point_size':0.18}, return_plot=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "elev = torch.deg2rad(torch.tensor(15)).to(device)\n",
    "azim = torch.deg2rad(torch.tensor(270)).to(device)\n",
    "r = 2.\n",
    "fov = np.pi / 3.\n",
    "image, face_idx = render_view(elev, azim, r)\n",
    "face_idx = face_idx.squeeze().cpu().numpy()\n",
    "img_to_show = image.copy()\n",
    "startX = 300; startY = 120; endX = 720; endY = 600\n",
    "bb = [(startX, startY), (endX, endY)]\n",
    "cv2.rectangle(img_to_show, (startX, startY), (endX, endY), [255,0,0], 2)\n",
    "plt.imshow(img_to_show)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = project_back_bb(bb, 1024, 1024,point_cloud, elev, azim, r, fov, face_idx, p)\n",
    "p = mp.plot(point_cloud, c = colors, shading = {'point_size':0.18}, return_plot=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "elev = torch.deg2rad(torch.tensor(15)).to(device)\n",
    "azim = torch.deg2rad(torch.tensor(70)).to(device)\n",
    "image, face_idx = render_view(elev, azim, 2)\n",
    "face_idx = face_idx.squeeze().cpu().numpy()\n",
    "img_to_show = image.copy()\n",
    "startX = 310; startY = 535; endX = 720; endY = 600\n",
    "bb = [(startX, startY), (endX, endY)]\n",
    "cv2.rectangle(img_to_show, (startX, startY), (endX, endY), [255,0,0], 2)\n",
    "plt.imshow(img_to_show)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = project_back_bb(bb, 1024, 1024, point_cloud, elev, azim, r, fov, face_idx, p)\n",
    "p = mp.plot(point_cloud, c = colors, shading = {'point_size':0.18}, return_plot=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "elev = torch.deg2rad(torch.tensor(40)).to(device)\n",
    "azim = torch.deg2rad(torch.tensor(130)).to(device)\n",
    "image, face_idx = render_view(elev, azim, 2)\n",
    "face_idx = face_idx.squeeze().cpu().numpy()\n",
    "img_to_show = image.copy()\n",
    "startX = 250; startY = 150; endX = 720; endY = 640\n",
    "bb = [(startX, startY), (endX, endY)]\n",
    "cv2.rectangle(img_to_show, (startX, startY), (endX, endY), [255,0,0], 2)\n",
    "plt.imshow(img_to_show)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = project_back_bb(bb, 1024, 1024,point_cloud, elev, azim, r, fov, face_idx, p)\n",
    "p = mp.plot(point_cloud, c = colors, shading = {'point_size':0.18}, return_plot=True)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "meshseg",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
