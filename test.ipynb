{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Torch will run on: cuda:0\n"
     ]
    }
   ],
   "source": [
    "# Imports and set torch device\n",
    "import numpy as np\n",
    "import meshplot as mp\n",
    "import matplotlib.pyplot as plt\n",
    "import kaolin as kal\n",
    "import cv2\n",
    "from collections import defaultdict\n",
    "import trimesh\n",
    "from scipy.spatial.distance import cdist\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda:0\")\n",
    "    torch.cuda.set_device(device)\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "\n",
    "print('Torch will run on:', device)\n",
    "\n",
    "object = 'bookshelf' \n",
    "obj_path = 'data/demo/' + object + '.obj'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of vertices:  5786\n",
      "Number of faces:  8624\n"
     ]
    }
   ],
   "source": [
    "# Read mesh\n",
    "mesh = kal.io.obj.import_mesh(\n",
    "    obj_path,\n",
    "    with_normals=True,\n",
    "    with_materials=False,\n",
    ")\n",
    "\n",
    "vertices_tensor = mesh.vertices.to(device)\n",
    "faces_tensor = mesh.faces.to(device)\n",
    "\n",
    "vertices = vertices_tensor.detach().cpu().numpy()\n",
    "faces = faces_tensor.detach().cpu().numpy()\n",
    "colors =  mesh.vertex_normals.cpu().numpy()\n",
    "\n",
    "print('Number of vertices: ', vertices.shape[0])\n",
    "print('Number of faces: ', faces.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5])\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor([1,2,3,5,6])\n",
    "print(x.unique().shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "only got 1842/2893 samples!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "02b7ab16df814d9792817c839103efe5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Renderer(camera=PerspectiveCamera(children=(DirectionalLight(color='white', intensity=0.6, position=(3.4272670â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\miniforge3\\envs\\test_proj\\lib\\site-packages\\traittypes\\traittypes.py:97: UserWarning: Given trait value dtype \"float32\" does not match required type \"float64\". A coerced copy has been created.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Visualize mesh\n",
    "trimeshMesh = trimesh.Trimesh(vertices, faces)\n",
    "# N = int(vertices.shape[0] * 2)\n",
    "N = int(vertices.shape[0] / 2)\n",
    "point_cloud, pt_to_face = trimesh.sample.sample_surface_even(trimeshMesh, N)\n",
    "torchPC = torch.tensor(point_cloud, device=torch.device('cuda:0'), dtype=torch.float32)\n",
    "face_to_all_pts = defaultdict(list)\n",
    "for pt in range(len(point_cloud)):\n",
    "    face_to_all_pts[pt_to_face[pt]].append(pt)\n",
    "p = mp.plot(vertices, faces, colors, return_plot=True, shading={\"wireframe\": 0.1})\n",
    "p.add_points(point_cloud, shading={\"point_size\": 0.1, \"point_color\": \"green\"})\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "elev = torch.deg2rad(torch.tensor([-45, 0, 45]))\n",
    "azim = torch.deg2rad(torch.tensor([0, 90, 180, 270]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 4]\n",
      " [1 4]\n",
      " [2 1]\n",
      " [3 2]\n",
      " [4 0]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import NearestNeighbors\n",
    "import numpy as np\n",
    "\n",
    "# Example data (replace this with your data loading code)\n",
    "# Assuming X contains your features\n",
    "X = np.array([[1, 2], [3, 4], [5, 6], [7, 8], [1,2.5]])\n",
    "\n",
    "# Instantiate KNN model\n",
    "nbrs = NearestNeighbors(n_neighbors=2, algorithm='ball_tree').fit(X)\n",
    "\n",
    "distances, indices = nbrs.kneighbors(X)\n",
    "\n",
    "# print(distances)\n",
    "\n",
    "print(indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "x = (np.random.randn(64,64,3) * 255).astype(np.uint8)\n",
    "\n",
    "p = Image.fromarray(x)\n",
    "p.save(f'TEST.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 2, 4])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "x = dict()\n",
    "x[1]=0\n",
    "x[2]=3\n",
    "x[4]=1\n",
    "print(torch.tensor(list(x.keys())))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "meshseg",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
